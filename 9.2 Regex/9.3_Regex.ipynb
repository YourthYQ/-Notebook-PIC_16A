{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bafa46b-aa69-49c0-8370-4f14d8686efb",
   "metadata": {},
   "source": [
    "Announcements:\n",
    "    \n",
    "- Week 10 schedule\n",
    "- Please fill out course evaluations!\n",
    "\n",
    "\n",
    "Earlier this week: Natural language processing. \n",
    "\n",
    "Today: regex (regular expression)\n",
    "\n",
    "\n",
    "# Regular Expressions\n",
    "\n",
    "https://docs.python.org/3/howto/regex.html#introduction\n",
    "\n",
    "\n",
    "\n",
    "Regular expressions are powerful tools to extract *structured information* from *unstructured text.*  For example, suppose that we are scraping Twitter data, and we'd like to extract a list of all the mentions and hashtags in a ~~tweet~~ X post. Our raw data might look something like this: \n",
    "\n",
    "<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">Our Great American Model was built on tough (very strong!!) parametric assumptions! <br><br>But FAR LEFT elitists living in coastal TANGENT SPACES (out of touch!) want to throw these out. Not on my watch!!<a href=\"https://twitter.com/hashtag/statstwitter?src=hash&amp;ref_src=twsrc%5Etfw\">#statstwitter</a> <a href=\"https://twitter.com/hashtag/epitwitter?src=hash&amp;ref_src=twsrc%5Etfw\">#epitwitter</a> <a href=\"https://twitter.com/hashtag/rstats?src=hash&amp;ref_src=twsrc%5Etfw\">#rstats</a> <a href=\"https://twitter.com/hashtag/math?src=hash&amp;ref_src=twsrc%5Etfw\">#math</a> <a href=\"https://twitter.com/hashtag/AI?src=hash&amp;ref_src=twsrc%5Etfw\">#AI</a> <a href=\"https://twitter.com/hashtag/DataScience?src=hash&amp;ref_src=twsrc%5Etfw\">#DataScience</a> <a href=\"https://twitter.com/hashtag/python?src=hash&amp;ref_src=twsrc%5Etfw\">#python</a> <a href=\"https://twitter.com/hashtag/Science?src=hash&amp;ref_src=twsrc%5Etfw\">#Science</a></p>&mdash; Statistician Trump (@StatisticianTr2) <a href=\"https://twitter.com/StatisticianTr2/status/1281959378371969024?ref_src=twsrc%5Etfw\">July 11, 2020</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>    \n",
    "\n",
    "We'd like to extract the hashtags from this ~~tweet~~post. For example, we'd like to write a function `collect_hashtags()` with the following output: \n",
    "\n",
    "```python\n",
    "collect_hashtags(tw)\n",
    "['statstwitter', 'epitwitter', 'rstats', 'math', 'AI', 'DataScience', 'python', 'Science']\n",
    "```\n",
    "\n",
    "We could then use this function on many ~~tweet~~posts in order to conduct an analysis of what people are talking about on ~~Twitter~~ X. How can we recognize the hashtags? \n",
    "\n",
    "If you're familiar with X, you know that a hashtag consists of the symbol \\#, followed by one or more letters, which may or may not be capitalized. A space `\" \"` terminates the hashtag. \n",
    "\n",
    "This is an informal description of a *pattern* -- a rule for detecting hashtags in text. In this case, the rule is: \n",
    "\n",
    "> Find a `#`. Then, continue through letters and numbers until a space `\" \"` is reached.\n",
    "\n",
    "Regular expressions allow us to formally construct and use patterns to obtain structured data like hashtags from unstructured text. They are an extremely powerful tool in any applications in which we need to work with text data. \n",
    "\n",
    "To work with regular expressions, we need a few functions from the `re` package. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a88cfe-1297-46fe-a435-37e899c202cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f410acda-d3a5-4e27-adab-d40c1c78c184",
   "metadata": {},
   "source": [
    "special metacharacters: `. ^ $ * + ? { } [ ] \\ | ( )`\n",
    "\n",
    "everything else, we can match one character at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185b2a94-b5b0-46aa-a7f9-ba9ecb451ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"california cat colony scale\"\n",
    "pattern = 'c' # look for character 'c' in string\n",
    "\n",
    "matches = re.findall(pattern, s)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154f55f0-0773-4d25-8d19-50ee52105392",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"california cat colony scale\"\n",
    "pattern = 'ca' # look for characters 'ca' in string\n",
    "\n",
    "matches = re.findall(pattern, s)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f662141-b0c7-426d-8383-5326e8b9c996",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"california cat colony\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8930280c-1874-4921-a8bb-735627ee3dfa",
   "metadata": {},
   "source": [
    "### Raw strings\n",
    "Actually, it is better to represent patterns as *raw strings*. They are preceded by `r` outside quotes. Raw strings don't process special characters. For example, the string `\"\\n\"` has just one character (the special newline character), but the string `r\"\\n\"` has two (`\"\\\"` and `\"n\"`).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9af926-f80a-4b35-9263-38bc10495130",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = 'hello\\nworld' # \"normal\" string so it reads \\n as a newline\n",
    "print(s1)\n",
    "print( )\n",
    "\n",
    "s2 = r'hello\\nworld' # raw string, ignores the special characters\n",
    "print(s2)\n",
    "\n",
    "# input(...) vs. raw_input(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914e5b2e-0728-4a32-80e4-e928e9ceb7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = '\\n'\n",
    "print(len(s1)) # should give 1\n",
    "\n",
    "s2 = r'\\n'\n",
    "print(len(s2)) # 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4868f746-a4b7-44d5-867b-d141670d03fb",
   "metadata": {},
   "source": [
    "### Character class\n",
    "\n",
    "`[  ]` , define a set, find anything in that set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb893702-9c69-4766-8d7f-af5f7ed6ea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"california cat colony\"\n",
    "pattern = '[abc]' # look for a character that is a, b, or c in a string\n",
    "\n",
    "matches = re.findall(pattern, s)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4df3aa-bca4-4e75-86ba-a89770dc4d93",
   "metadata": {},
   "source": [
    "complement of this class: `^` (everything but)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bcbfb6-8053-4589-b176-149e99c84df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"california cat colony\"\n",
    "pattern = '[^a-g]' # look for a character that is NOT a, b, .. g in a string\n",
    "\n",
    "matches = re.findall(pattern, s)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5adcff-91c0-4bd7-b245-902f1cad8637",
   "metadata": {},
   "source": [
    "\n",
    "`\\d`\n",
    "\n",
    "    Matches any decimal digit; this is equivalent to the class [0-9].\n",
    "`\\D`\n",
    "\n",
    "    Matches any non-digit character; this is equivalent to the class [^0-9].\n",
    "`\\s`\n",
    "\n",
    "    Matches any whitespace character; this is equivalent to the class [ \\t\\n\\r\\f\\v].\n",
    "`\\S`\n",
    "\n",
    "    Matches any non-whitespace character; this is equivalent to the class [^ \\t\\n\\r\\f\\v].\n",
    "`\\w`\n",
    "\n",
    "    Matches any alphanumeric character; this is equivalent to the class [a-zA-Z0-9_].\n",
    "`\\W`\n",
    "\n",
    "    Matches any non-alphanumeric character; this is equivalent to the class [^a-zA-Z0-9_].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aca7fc6-61f0-4da0-ab8f-03cc5dcda7d4",
   "metadata": {},
   "source": [
    "escape meta characters: `\\`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1d3e21-593e-4c21-a4ba-6032a9de1772",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"what^s [up]\"\n",
    "pattern = r'\\[' # look for the character '[', not interpreting it as a special character\n",
    "#pattern = r'['\n",
    "\n",
    "matches = re.findall(pattern, s)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6477713e-7a0f-410d-80cb-640f50d247d6",
   "metadata": {},
   "source": [
    "match any single character except line terminators: ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de5ba99-ff2d-4b80-8101-3fb718732490",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"california cat colony 999 kafhlq6817468!!?\"\n",
    "pattern = r'.' \n",
    "\n",
    "matches = re.findall(pattern, s)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1592c3f-f5a7-4b3c-bedb-9b25df937f54",
   "metadata": {},
   "source": [
    "### Repeating things\n",
    "    \n",
    "`*` : zero or more times\n",
    "\n",
    "`+` : one or more times\n",
    "\n",
    "`?` : zero or one time (think of it being optional, like multi-national or multinational)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65c62a4-e1cc-4a0b-9c8b-4ee21bcdc62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'ct cat caat caaat caaaaaaaaaat'\n",
    "#pattern = r'ca*t' # look for something that is c + a (zero or more times) + t\n",
    "#pattern = r'ca+t' # c + a (one or more times) + t\n",
    "pattern = r'ca?t' # c + a (zero or one time) + t\n",
    "\n",
    "matches = re.findall(pattern, s)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac6331b-a89e-4a21-a281-6ed07c0c114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'multi-national multinational'\n",
    "pattern = r'multi-?national'\n",
    "\n",
    "matches = re.findall(pattern, s)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaccb991-f4fb-4a92-b11e-6de6bc61ea15",
   "metadata": {},
   "source": [
    "### Example: tweet (uh, X post)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9feac84-46de-4a21-94c9-c3fdc4bad256",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"Our Great American Model was built on tough (very strong!!) parametric assumptions! \\\n",
    "But FAR LEFT elitists living in coastal TANGENT SPACES (out of touch!) want to throw these out.\\\n",
    "Not on my watch!! #statstwitter #epitwitter #rstats #math #AI #DataScience #python #Science\" \n",
    "s\n",
    "\n",
    "# look for # and then some characters and then once you hit a space, end there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6a106d-b7f0-4347-8942-6a26c692a630",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'#\\w+' # look for # + one or more alphanumeric characters\n",
    "\n",
    "matches = re.findall(pattern, s)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8628ad-5d78-4ff9-98c1-f1eaad73c1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'GAME ON, Bruins! ðŸ€ \\\n",
    "Mini basketballs, @ASUCLAStudentU coupon books and other giveaways await you at the #UCLAfirstthursdays block party!'\n",
    "\n",
    "pattern = r'[#@]\\w+' # look for [# or @] + one or more alphanumeric characters\n",
    "\n",
    "matches = re.findall(pattern, s)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294401fc-57e1-4a20-ba52-8da0e46adc60",
   "metadata": {},
   "source": [
    "### Groups: parsing email addresses\n",
    "Suppose that we'd like to extract some email addresses from a body of text. For example: \n",
    "\n",
    "> You can reach me at kose@math.ucla.edu or kos@ucla.edu or kos@g.ucla.edu.\n",
    "\n",
    "We'd like to extract the usernames and domains of each of these email addresses. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9d2d0c-17fd-4267-8746-ac0292dcd3b1",
   "metadata": {},
   "source": [
    "For this we can use **groups**. Groups allow us to give names to \"parts\" of matches, enabling further processing. \n",
    "\n",
    "Intuitively, we are looking for: \n",
    "\n",
    "1. **The username**: A sequence of one or more letters and numbers, followed by \n",
    "2. An `@` symbol, followed by  \n",
    "3. **The domain:** another sequence of characters, numbers, or the symbol `.`.\n",
    "4. We should not include the final `.` in the domain name for Picard. \n",
    "\n",
    "To see how groups work, let's take a look at an interactive demonstration in [Pythex](https://pythex.org/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed030c45-99b2-476e-9a76-1f28de12da88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s = \"You can reach me at kose@math.ucla.edu or kos@ucla.edu or kos@g.ucla.edu.\"\n",
    "\n",
    "# characters + @ + [characters and . ] + characters\n",
    "\n",
    "pattern = r'\\w+@[\\w\\.]+\\w' # \n",
    "\n",
    "matches = re.findall(pattern, s)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96197d27-a0c1-447d-88d0-32a3471cc85b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pattern = r\"([A-z0-9]+)@([a-z\\.]+[a-z]+)\"\n",
    "result = re.search(pattern, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3d851f-da66-4056-a169-a9e891fbed1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "re.findall(pattern, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c2853b-23d9-4b5e-b71d-503ec6832cf3",
   "metadata": {},
   "source": [
    "### Example: Parsing HTML\n",
    "\n",
    "there are tons of online tools for regex: \n",
    "\n",
    "https://pythex.org/\n",
    "\n",
    "https://regexr.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50be3c3-9451-4b1c-a589-67a772c17fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "url = \"https://www.ucla.edu/\"\n",
    "\n",
    "page = urlopen(url)\n",
    "html_bits = page.read()\n",
    "\n",
    "html = html_bits.decode('latin-1')\n",
    "\n",
    "print(html[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7255b111-2c6d-48d3-8991-e0ec30ac3c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = re.findall(r'href=[\\'\"]?([^\\'\">]+)', html)\n",
    "\n",
    "urls\n",
    "\n",
    "[url for url in urls if \"http\" in url]\n",
    "# ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9fde14-27bd-49c7-b1f7-d536dbec3f5b",
   "metadata": {},
   "source": [
    "### Parsing Unstructured Scientific Data\n",
    "\n",
    "Sometimes, data doesn't come to us neatly wrapped in CSV files. For example, consider the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1ab0d2-e55d-45ae-bf59-2d29aaeec21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"\"\"\n",
    "Andrea    5:31\n",
    "Ben       5:02\n",
    "Carl      6:21\n",
    "Didi      5:10\n",
    "\"\"\"\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d427294c-f309-4a00-b963-0632fd1744c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "Since it looks like these data represent times, let's parse the data into names, minutes, and seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3c5174-72d4-48d0-8ab9-8cef38bf4b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"([A-z]+)\\s+(\\d+):(\\d+)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf85d18-9c3b-4a11-93d5-b9ba66dd3322",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = re.findall(pattern, data)\n",
    "parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7684008a-bbff-420c-900f-332ec0b7ef06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "{p[0] : 60*int(p[1]) + int(p[2]) for p in parsed}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
